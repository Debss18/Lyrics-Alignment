{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "##import Libraries\n",
        "import pickle\n",
        "import librosa\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "MTDbc9W74BTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Feature extraction for entire folder"
      ],
      "metadata": {
        "id": "3KAIIExfFkf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_audio_features(audio_filename, output_dir):\n",
        "    # Load audio file\n",
        "    y, sr = librosa.load(audio_filename, sr=None)\n",
        "    duration = librosa.get_duration(y=y, sr=sr)\n",
        "    segment_length = 30  # Segment length in seconds\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Dictionary to store results\n",
        "    audio_features = {}\n",
        "\n",
        "    # Divide audio into 30-second segments\n",
        "    num_segments = int(np.ceil(duration / segment_length))\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        start_sample = int(i * segment_length * sr)\n",
        "        end_sample = int(min((i + 1) * segment_length * sr, len(y)))\n",
        "        segment = y[start_sample:end_sample]\n",
        "\n",
        "        # Generate spectrogram\n",
        "        S = librosa.stft(segment, hop_length = sr*0.01)\n",
        "        S_db = librosa.amplitude_to_db(np.abs(S), ref=np.max)\n",
        "\n",
        "        # Extract MFCCs\n",
        "        mfccs = librosa.feature.mfcc(y=segment, sr=sr, n_mfcc=20, hop_length = sr*0.01)\n",
        "\n",
        "        # F_0 estimation\n",
        "        time, frequency, confidence, activation = estimate_pitch(segment, sr, voicing_threshold=0.3, use_viterbi=True)\n",
        "\n",
        "        # Split the file name and extension\n",
        "        file_name, file_extension = os.path.splitext(audio_filename)\n",
        "\n",
        "        # Create the segment name\n",
        "        segment_name = f\"{file_name}_segment_{i+1}{file_extension}\"\n",
        "\n",
        "        # Store the features in the dictionary\n",
        "        audio_features[segment_name] = {\n",
        "            \"spectrogram\": S_db,\n",
        "            \"mfcc\": mfccs[1:], # remove first row of mfcc\n",
        "            \"f_0 estimation\": frequency\n",
        "        }\n",
        "\n",
        "    output_file = os.path.join(output_dir, f\"{file_name}_features.pkl\")\n",
        "    with open(output_file, 'wb') as f:\n",
        "        pickle.dump(audio_features, f)\n",
        "\n",
        "\n",
        "    return audio_features"
      ],
      "metadata": {
        "id": "_Plhz7FrDTVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_audio_folder(folder_path, output_dir):\n",
        "    \"\"\"\n",
        "    Processes all .wav files in the given folder and generates audio features.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    folder_path : str\n",
        "        Path to the folder containing audio files.\n",
        "    output_dir : str\n",
        "        Directory where processed features will be saved.\n",
        "    \"\"\"\n",
        "    # List all .wav files in the folder\n",
        "    audio_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.wav')]\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Process each file\n",
        "    for audio_file in audio_files:\n",
        "        print(f\"Processing: {audio_file}\")\n",
        "        generate_audio_features(audio_file, output_dir)\n",
        "        print(f\"Finished processing: {audio_file}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "jPhMQdIOvDjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_combined_feature_input(spectrogram, mfcc, f0):\n",
        "    # Add channel dimension and stack features\n",
        "\n",
        "    spectrogram = spectrogram[np.newaxis, :, :]  # Shape: (1, frequency_bins, time_frames)\n",
        "    mfcc = mfcc[np.newaxis, :, :]  # Shape: (1, n_mfcc, time_frames)\n",
        "    f0 = f0[np.newaxis, np.newaxis, :]  # Shape: (1, 1, time_frames)\n",
        "\n",
        "    # Combine spectrogram, MFCC, and f0 into a single input\n",
        "    combined_feature = np.concatenate([spectrogram, mfcc, f0], axis=1)\n",
        "    return combined_feature"
      ],
      "metadata": {
        "id": "SJJUfRgfQnFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Songsay_output_features/1047_v360P_V1_source_3_features.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "test_item = data['1047_v360P_V1_source_3_segment_1.wav']\n",
        "test_spec = test_item['spectrogram']\n",
        "test_mfcc = test_item['mfcc']\n",
        "test_f0 = test_item['f_0 estimation']\n",
        "combined_input = create_combined_feature_input(test_spec, test_mfcc, test_f0)"
      ],
      "metadata": {
        "id": "DuEfpAuiOnNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_spec.shape #(1025, 3001)\n",
        "test_mfcc.shape #(19, 3001)"
      ],
      "metadata": {
        "id": "-IxHO_m9PSyl",
        "outputId": "9a7910c8-363a-4168-ad3c-e891289c3d60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19, 3001)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(test_f0))"
      ],
      "metadata": {
        "id": "2gZNQC3VP58L",
        "outputId": "3a22a252-d417-43b2-b455-805dd9352292",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3001"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_input.shape"
      ],
      "metadata": {
        "id": "0czCBtP8vUvq",
        "outputId": "5651955b-a561-4bb0-ffc6-6d2965887a91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1045, 3001)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_combined_features_from_pkl(pkl_file_path, output_dir):\n",
        "    # Load the .pkl file containing audio features\n",
        "    with open(pkl_file_path, 'rb') as f:\n",
        "        audio_features = pickle.load(f)\n",
        "\n",
        "    # Create output directory if it doesn't exist\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Dictionary to store combined features\n",
        "    combined_features = {}\n",
        "\n",
        "    # Iterate through each segment in the pkl file and create combined feature input\n",
        "    for segment_name, features in audio_features.items():\n",
        "        spectrogram = features['spectrogram']\n",
        "        mfcc = features['mfcc']\n",
        "        f0 = features['f_0 estimation']\n",
        "\n",
        "        # Create combined feature\n",
        "        combined_feature = create_combined_feature_input(spectrogram, mfcc, f0)\n",
        "\n",
        "        # Store the combined feature in the dictionary\n",
        "        combined_features[segment_name] = combined_feature\n",
        "\n",
        "    # Save the combined features to a new .pkl file\n",
        "    output_file = os.path.join(output_dir, os.path.basename(pkl_file_path).replace('.pkl', '_combined.pkl'))\n",
        "    with open(output_file, 'wb') as f:\n",
        "        pickle.dump(combined_features, f)\n",
        "\n",
        "    return combined_features\n",
        "\n",
        "def process_all_pkl_files(input_folder, output_folder):\n",
        "    # Iterate through all .pkl files in the input folder\n",
        "    for file_name in os.listdir(input_folder):\n",
        "        if file_name.endswith('.pkl'):\n",
        "            pkl_file_path = os.path.join(input_folder, file_name)\n",
        "            # Generate combined features for each .pkl file\n",
        "            generate_combined_features_from_pkl(pkl_file_path, output_folder)\n",
        "\n",
        "process_all_pkl_files(\"/content/drive/MyDrive/Songsay_output_features\", \"/content/drive/MyDrive/concat_features_nobeats\" )"
      ],
      "metadata": {
        "id": "PK88LOSD1hrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##concatenate features along time axis\n",
        "def concatenate_segments_for_audio(input_folder, output_folder):\n",
        "    # Iterate through all _combined.pkl files in the input folder\n",
        "    for file_name in os.listdir(input_folder):\n",
        "        if file_name.endswith('_combined.pkl'):\n",
        "            pkl_file_path = os.path.join(input_folder, file_name)\n",
        "\n",
        "            # Load combined features from pkl file\n",
        "            with open(pkl_file_path, 'rb') as f:\n",
        "                combined_features = pickle.load(f)\n",
        "\n",
        "            # Concatenate all segments along the time axis\n",
        "            concatenated_feature = np.concatenate([segment for segment in combined_features.values()], axis=2)  # Concatenate along the time axis\n",
        "\n",
        "            # Save the concatenated feature to a new .pkl file\n",
        "            output_file = os.path.join(output_folder, file_name.replace('_combined.pkl', '_concatenated.pkl'))\n",
        "            with open(output_file, 'wb') as f:\n",
        "                pickle.dump(concatenated_feature, f)\n",
        "\n",
        "concatenate_segments_for_audio(\"/content/drive/MyDrive/concat_features_nobeats\", \"/content/drive/MyDrive/concat_features_nobeats_unsegmented\")"
      ],
      "metadata": {
        "id": "Rkr1UzvlANcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/concat_features_nobeats_unsegmented/10932_v360P_V1_source_3_features_concatenated.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)"
      ],
      "metadata": {
        "id": "vuJEVyyVDH_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "WS-JWgGUDOjR",
        "outputId": "10eb9a32-0989-4570-cb93-ec0a473a312b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-8.00000000e+01, -8.00000000e+01, -8.00000000e+01, ...,\n",
              "         -7.63258743e+01, -7.12796326e+01, -6.90777817e+01],\n",
              "        [-7.92051697e+01, -8.00000000e+01, -8.00000000e+01, ...,\n",
              "         -6.91974716e+01, -7.26264038e+01, -7.13789749e+01],\n",
              "        [-7.70871811e+01, -7.70083771e+01, -8.00000000e+01, ...,\n",
              "         -8.00000000e+01, -7.90651627e+01, -7.42696228e+01],\n",
              "        ...,\n",
              "        [-2.78383160e+00, -2.98514605e+00, -5.51406801e-01, ...,\n",
              "         -1.24940510e+01, -1.12014341e+01, -7.21944618e+00],\n",
              "        [-2.61022711e+00, -2.84083462e+00, -5.35616040e-01, ...,\n",
              "          1.83486927e+00,  4.38358974e+00,  4.94402170e+00],\n",
              "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
              "          7.51149134e+02,  7.52148783e+02,  7.52513604e+02]]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loader"
      ],
      "metadata": {
        "id": "SezxOMQ26zWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pkl_folder = \"/content/drive/MyDrive/concat_features_nobeats_unsegmented\"\n",
        "ground_truth_folder = \"/content/drive/MyDrive/ground_truth/\""
      ],
      "metadata": {
        "id": "umTYdM7_50pB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "class PKLDataLoader(tf.keras.utils.Sequence):\n",
        "    def __init__(self, pkl_folder, ground_truth_folder, batch_size, max_feature_length, num_classes=8):\n",
        "        self.pkl_folder = pkl_folder\n",
        "        self.ground_truth_folder = ground_truth_folder\n",
        "        self.batch_size = batch_size\n",
        "        self.pkl_files = [f for f in os.listdir(pkl_folder) if f.endswith(\".pkl\")]\n",
        "        self.max_feature_length = max_feature_length\n",
        "        self.num_classes = num_classes  # Fixed number of output classes\n",
        "\n",
        "    def __len__(self):\n",
        "        # Number of batches per epoch\n",
        "        return int(np.ceil(len(self.pkl_files) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get batch file names\n",
        "        batch_files = self.pkl_files[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        X_batch = []\n",
        "        Y_batch = []\n",
        "\n",
        "        for pkl_file in batch_files:\n",
        "            audio_id = os.path.splitext(pkl_file)[0]\n",
        "\n",
        "            # Load feature file\n",
        "            pkl_path = os.path.join(self.pkl_folder, pkl_file)\n",
        "            with open(pkl_path, \"rb\") as f:\n",
        "                features = pickle.load(f)\n",
        "                features = np.array(features)\n",
        "                # Pad features to global max length\n",
        "                padding_length = self.max_feature_length - features.shape[2]\n",
        "                if padding_length > 0:\n",
        "                    features = np.pad(features, ((0, 0), (0, 0), (0, padding_length)), mode=\"constant\")\n",
        "                X_batch.append(np.squeeze(features))  # Remove unnecessary dimensions\n",
        "\n",
        "            # Load and adjust target file\n",
        "            txt_path = os.path.join(self.ground_truth_folder, f\"{audio_id}.txt\")\n",
        "            data = pd.read_csv(\n",
        "                txt_path,\n",
        "                header=None,\n",
        "                delimiter=\",\",\n",
        "                usecols=[0],\n",
        "                on_bad_lines=\"skip\",\n",
        "                engine=\"python\"\n",
        "            )\n",
        "            targets = data.iloc[:, 0].values\n",
        "\n",
        "            # Truncate or pad to num_classes\n",
        "            targets = targets[:self.num_classes]  # Truncate\n",
        "            if len(targets) < self.num_classes:\n",
        "                targets = np.pad(targets, (0, self.num_classes - len(targets)), mode=\"constant\")\n",
        "\n",
        "            Y_batch.append(targets)\n",
        "\n",
        "        # Stack and return the batch\n",
        "        X_batch = np.stack(X_batch, axis=0)\n",
        "        Y_batch = np.stack(Y_batch, axis=0)\n",
        "        return X_batch, Y_batch\n"
      ],
      "metadata": {
        "id": "v8gYWqj13jBj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_feature_length = 44107\n",
        "max_target_length = 8\n",
        "\n",
        "\n",
        "# Get the list of all .pkl files\n",
        "pkl_files = [f for f in os.listdir(pkl_folder) if f.endswith(\".pkl\")]\n",
        "\n",
        "# Get the list of all .txt files\n",
        "txt_files = [f for f in os.listdir(ground_truth_folder) if f.endswith(\".txt\")]\n",
        "\n",
        "# Extract audio IDs (filenames without extensions)\n",
        "pkl_ids = set(os.path.splitext(f)[0] for f in pkl_files)\n",
        "txt_ids = set(os.path.splitext(f)[0] for f in txt_files)\n",
        "\n",
        "# Find the joint set of IDs\n",
        "joint_ids = pkl_ids.intersection(txt_ids)\n",
        "\n",
        "# Filter the .pkl files to retain only those with a matching .txt file\n",
        "filtered_pkl_files = [f\"{audio_id}.pkl\" for audio_id in joint_ids]\n",
        "\n",
        "# Filter the .txt files to retain only those with a matching .pkl file\n",
        "filtered_txt_files = [f\"{audio_id}.txt\" for audio_id in joint_ids]\n",
        "\n",
        "print(f\"Number of matching .pkl and .txt files: {len(joint_ids)}\")\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # Split the filtered .pkl files into train and test sets\n",
        "train_files, test_files = train_test_split(filtered_pkl_files, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create DataLoaders for training and testing\n",
        "train_loader = PKLDataLoader(\n",
        "    pkl_folder=pkl_folder,\n",
        "    ground_truth_folder=ground_truth_folder,\n",
        "    batch_size=2,\n",
        "    max_feature_length=max_feature_length,\n",
        "    num_classes = max_target_length,\n",
        "\n",
        ")\n",
        "train_loader.pkl_files = train_files  # Assign train files to the loader\n",
        "\n",
        "test_loader = PKLDataLoader(\n",
        "    pkl_folder=pkl_folder,\n",
        "    ground_truth_folder=ground_truth_folder,\n",
        "    batch_size=2,\n",
        "    max_feature_length=max_feature_length,\n",
        "    num_classes = max_target_length,\n",
        "\n",
        ")\n",
        "test_loader.pkl_files = test_files  # Assign test files to the loader\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_3EZIF_3rWv",
        "outputId": "8cdd1c3f-395a-480b-e0ce-8d6f7e860c2a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of matching .pkl and .txt files: 88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model Training"
      ],
      "metadata": {
        "id": "vxJSvIinAWBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With num_classes = 162 classes, 5 epochs"
      ],
      "metadata": {
        "id": "hUP6oDdgEZtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get input shape dynamically from DataLoader\n",
        "first_batch_X, _ = train_loader[0]  # Fetch the first batch\n",
        "input_shape = (first_batch_X.shape[1], first_batch_X.shape[2])  # (sequence_length, features_per_time_step)\n",
        "\n",
        "# Define the number of classes for classification\n",
        "num_classes = 162\n",
        "\n",
        "# Build the classification CNN model\n",
        "model = Sequential([\n",
        "    Conv1D(64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv1D(128, kernel_size=3, activation='relu'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv1D(256, kernel_size=3, activation='relu'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv1D(512, kernel_size=3, activation='relu'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),  # Dropout to reduce overfitting\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')  # Classification output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model using the DataLoader\n",
        "model.fit(train_loader, epochs=5, validation_data=test_loader)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(test_loader)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "Y_true = []\n",
        "Y_pred = []\n",
        "\n",
        "for X_batch, Y_batch in test_loader:\n",
        "    # print(\"!!!\", X_batch)\n",
        "    # print(\"!!!!!\", Y_batch)\n",
        "    Y_hat = model.predict(X_batch)\n",
        "    Y_true.extend(np.argmax(Y_batch, axis=1))  # Convert one-hot to class indices\n",
        "    Y_pred.extend(np.argmax(Y_hat, axis=1))\n",
        "\n",
        "# Calculate classification accuracy\n",
        "accuracy = accuracy_score(Y_true, Y_pred)\n",
        "print(f\"Classification Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Save predictions and model\n",
        "np.savetxt(\"/content/drive/MyDrive/predictions_Y_hat.txt\", Y_pred, fmt=\"%d\", header=\"Predicted Classes\")\n",
        "model.save(\"/content/drive/MyDrive/cnn_classification_model.h5\")\n",
        "\n",
        "print(\"Model and predictions saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-jPGkDqNJ5fw",
        "outputId": "4c7d1131-7025-4fd0-b65b-4a7e23737ab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 2/35\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 341ms/step - accuracy: 0.0000e+00 - loss: 43808.7969   !!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 3/35\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:56\u001b[0m 9s/step - accuracy: 0.0000e+00 - loss: 57768.3906  !!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 4/35\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:46\u001b[0m 7s/step - accuracy: 0.0000e+00 - loss: 63440.9922!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 5/35\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:19\u001b[0m 11s/step - accuracy: 0.0000e+00 - loss: 68061.1719!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 6/35\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:09\u001b[0m 13s/step - accuracy: 0.0000e+00 - loss: 77284.9062!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 7/35\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:52\u001b[0m 15s/step - accuracy: 0.0000e+00 - loss: 90862.7734!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 8/35\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:50\u001b[0m 15s/step - accuracy: 0.0000e+00 - loss: 100442.5859!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 9/35\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:55\u001b[0m 16s/step - accuracy: 0.0000e+00 - loss: 111975.3750!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m10/35\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:08\u001b[0m 17s/step - accuracy: 0.0000e+00 - loss: 130721.7734!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m11/35\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:54\u001b[0m 17s/step - accuracy: 0.0000e+00 - loss: 151663.0156!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m12/35\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:50\u001b[0m 18s/step - accuracy: 0.0000e+00 - loss: 174796.9531!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m13/35\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m6:43\u001b[0m 18s/step - accuracy: 0.0000e+00 - loss: 197667.1406!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m14/35\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6:29\u001b[0m 19s/step - accuracy: 0.0000e+00 - loss: 222096.9844!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m15/35\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m6:27\u001b[0m 19s/step - accuracy: 0.0000e+00 - loss: 248790.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m16/35\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m6:10\u001b[0m 20s/step - accuracy: 0.0000e+00 - loss: 275841.1875!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m17/35\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5:56\u001b[0m 20s/step - accuracy: 0.0000e+00 - loss: 302940.8438!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m18/35\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5:37\u001b[0m 20s/step - accuracy: 0.0000e+00 - loss: 326579.4062!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m19/35\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m5:27\u001b[0m 20s/step - accuracy: 0.0000e+00 - loss: 348113.1562!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m20/35\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m5:11\u001b[0m 21s/step - accuracy: 0.0000e+00 - loss: 372087.8750!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m21/35\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4:48\u001b[0m 21s/step - accuracy: 0.0000e+00 - loss: 396928.0938!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m22/35\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4:18\u001b[0m 20s/step - accuracy: 0.0000e+00 - loss: 445394.2812!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m23/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4:00\u001b[0m 20s/step - accuracy: 0.0000e+00 - loss: 497720.3750!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m24/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3:43\u001b[0m 20s/step - accuracy: 0.0000e+00 - loss: 553827.7500!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m25/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3:25\u001b[0m 21s/step - accuracy: 0.0000e+00 - loss: 606221.2500!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m26/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3:03\u001b[0m 20s/step - accuracy: 0.0000e+00 - loss: 661476.2500!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m27/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2:46\u001b[0m 21s/step - accuracy: 0.0000e+00 - loss: 717232.8125!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16s/step - accuracy: 0.0031 - loss: 1172543.8750 !!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m905s\u001b[0m 22s/step - accuracy: 0.0034 - loss: 1237972.8750 - val_accuracy: 0.0556 - val_loss: 3972120.5000\n",
            "Epoch 2/5\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32:52\u001b[0m 58s/step - accuracy: 0.0000e+00 - loss: 22358892.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 2/35\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:13\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 19153448.0000  !!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 3/35\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:27\u001b[0m 5s/step - accuracy: 0.0000e+00 - loss: 17521552.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 4/35\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:15\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 16860654.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 5/35\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:05\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 16564856.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 6/35\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:03\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 16358136.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 7/35\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:58\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 16510281.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 8/35\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:54\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 16496597.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 9/35\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 16852716.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m10/35\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 17561020.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m11/35\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 18261020.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m12/35\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 18798976.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m13/35\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 19199562.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m14/35\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:26\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 19629780.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m15/35\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:23\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 19968640.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m16/35\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:20\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 20357940.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m17/35\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:16\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 20654844.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m18/35\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:12\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 20896690.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m19/35\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:07\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 21200674.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m20/35\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 21471674.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m21/35\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 21841548.0000 !!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m22/35\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 22240476.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m23/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 22617570.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m24/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 23015248.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m25/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 23390910.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m26/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 23772168.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m27/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m34s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 24145590.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: 30977698.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 5s/step - accuracy: 0.0000e+00 - loss: 31731630.0000 - val_accuracy: 0.0556 - val_loss: 49124728.0000\n",
            "Epoch 3/5\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23:57\u001b[0m 42s/step - accuracy: 0.0000e+00 - loss: 100966584.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 2/35\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:58\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 101408448.0000  !!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 3/35\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:07\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 110140784.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 4/35\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:11\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 111906368.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 5/35\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:03\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 111904792.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 6/35\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:03\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 111898344.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 7/35\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:01\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 113059088.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 8/35\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:59\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 114579640.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 9/35\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:54\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 115829840.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m10/35\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 118520288.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m11/35\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 120226976.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m12/35\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 121458968.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m13/35\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 130481360.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m14/35\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:31\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 139663744.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m15/35\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:25\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 147335456.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m16/35\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:19\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 154800304.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m17/35\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:15\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 160877216.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m18/35\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:12\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 166815520.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m19/35\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:07\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 171743728.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m20/35\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:02\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 176832512.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m21/35\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 181043152.0000 !!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m22/35\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 184824240.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m23/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 188424416.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m24/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 191595136.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m25/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 195419392.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m26/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 199934416.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m27/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m33s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 204405888.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: 237538160.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 240894688.0000 - val_accuracy: 0.0556 - val_loss: 448367936.0000\n",
            "Epoch 4/5\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31:08\u001b[0m 55s/step - accuracy: 0.0000e+00 - loss: 235159920.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 2/35\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:14\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 242979232.0000  !!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 3/35\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:04\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 231374896.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 4/35\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:10\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 265116720.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 5/35\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:08\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 349238432.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 6/35\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:57\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 407241088.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 7/35\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:58\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 452572928.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 8/35\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 487032608.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 9/35\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 508929472.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m10/35\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 528018464.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m11/35\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 540893760.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m12/35\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 549175360.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m13/35\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 555270528.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m14/35\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:28\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 559269632.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m15/35\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:23\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 564045376.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m16/35\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:19\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 579117952.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m17/35\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:15\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 597317824.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m18/35\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:10\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 612414208.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m19/35\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:07\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 625094720.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m20/35\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 639779328.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m21/35\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 679581184.0000 !!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m22/35\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 713305408.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m23/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 745334784.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m24/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 774071616.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m25/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 800597760.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m26/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 825421376.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m27/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m34s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 847032192.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: 1003415552.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 1020195456.0000 - val_accuracy: 0.0556 - val_loss: 2479665664.0000\n",
            "Epoch 5/5\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19:28\u001b[0m 34s/step - accuracy: 0.0000e+00 - loss: 6810084864.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 2/35\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:03\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 5301772800.0000  !!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 3/35\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:02\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 4769977344.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 4/35\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:15\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 4431914496.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 5/35\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:03\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 4110579456.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 6/35\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:55\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3865337600.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 7/35\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:57\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3654651648.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 8/35\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3481757952.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m 9/35\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3348090624.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m10/35\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3229515776.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m11/35\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3175074048.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m12/35\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3124872704.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m13/35\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3097419264.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m14/35\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:29\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3078277120.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m15/35\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:24\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3077019136.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m16/35\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:20\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3082826496.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m17/35\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:15\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3112072960.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m18/35\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:11\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3129913088.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m19/35\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3139973120.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m20/35\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3142824704.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m21/35\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3145396480.0000 !!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m22/35\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3143475712.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m23/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3141651712.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m24/35\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3140510208.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m25/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3201721088.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m26/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3255186176.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m27/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m34s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3300974848.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: 3530955520.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3555004672.0000 - val_accuracy: 0.0556 - val_loss: 4988802560.0000\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: 6442171392.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m2/9\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: 4916644352.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m3/9\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 4200651520.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m4/9\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3715694592.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m5/9\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3424451584.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m6/9\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3292078848.0000!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m7/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m7s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3150723584.0000 !!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m8/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 4s/step - accuracy: 0.0078 - loss: 3010147584.0000    !!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 4s/step - accuracy: 0.0174 - loss: 3405878528.0000\n",
            "Test Loss: 4988802560.0, Test Accuracy: 0.0555555559694767\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step\n",
            "!!! (2, 1045, 44107)\n",
            "!!!!! (2, 162)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step\n",
            "!!! (0,)\n",
            "!!!!! (0,)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "need at least one array to stack",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-42ee7fc8392d>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;31m# print(\"!!!\", X_batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# print(\"!!!!!\", Y_batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-07e7c38787a2>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!!!!!\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Stack and return the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mY_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need at least one array to stack'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: need at least one array to stack"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With num_classes = 8 classes, 20 epochs"
      ],
      "metadata": {
        "id": "6CEPQSwSFIyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get input shape dynamically from DataLoader\n",
        "first_batch_X, _ = train_loader[0]  # Fetch the first batch\n",
        "input_shape = (first_batch_X.shape[1], first_batch_X.shape[2])  # (sequence_length, features_per_time_step)\n",
        "\n",
        "# Define the number of classes for classification\n",
        "num_classes = 8\n",
        "\n",
        "# Build the classification CNN model\n",
        "model = Sequential([\n",
        "    Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv1D(64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv1D(128, kernel_size=3, activation='relu'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),  # Dropout to reduce overfitting\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')  # Classification output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model using the DataLoader\n",
        "model.fit(train_loader, epochs=20, validation_data=test_loader)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(test_loader)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "\n",
        "model.save(\"/content/drive/MyDrive/cnn_classification_model_20ep.h5\")\n",
        "\n",
        "print(\"Model and predictions saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aps0ZbgIj8Z",
        "outputId": "c7e1570a-b2cf-4a91-c790-3b8bd346a68b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - accuracy: 0.1510 - loss: 11458.3662 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1053s\u001b[0m 25s/step - accuracy: 0.1540 - loss: 11956.4570 - val_accuracy: 0.8889 - val_loss: 36377.4180\n",
            "Epoch 2/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 4s/step - accuracy: 0.3287 - loss: 145335.0625 - val_accuracy: 0.2222 - val_loss: 62955.8828\n",
            "Epoch 3/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 4s/step - accuracy: 0.1945 - loss: 622866.8125 - val_accuracy: 0.0000e+00 - val_loss: 270353.4375\n",
            "Epoch 4/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 4s/step - accuracy: 0.1973 - loss: 1968755.2500 - val_accuracy: 0.1111 - val_loss: 678731.9375\n",
            "Epoch 5/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 4s/step - accuracy: 0.3320 - loss: 4437678.0000 - val_accuracy: 0.0556 - val_loss: 2555081.2500\n",
            "Epoch 6/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 4s/step - accuracy: 0.3588 - loss: 10715494.0000 - val_accuracy: 1.0000 - val_loss: 3195199.5000\n",
            "Epoch 7/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 4s/step - accuracy: 0.3849 - loss: 18160890.0000 - val_accuracy: 1.0000 - val_loss: 12222801.0000\n",
            "Epoch 8/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 4s/step - accuracy: 0.5822 - loss: 30394784.0000 - val_accuracy: 1.0000 - val_loss: 17126038.0000\n",
            "Epoch 9/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 4s/step - accuracy: 0.6019 - loss: 52712308.0000 - val_accuracy: 1.0000 - val_loss: 33702060.0000\n",
            "Epoch 10/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - accuracy: 0.5604 - loss: 61403140.0000 - val_accuracy: 1.0000 - val_loss: 43417428.0000\n",
            "Epoch 11/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 4s/step - accuracy: 0.5790 - loss: 93596432.0000 - val_accuracy: 1.0000 - val_loss: 77077296.0000\n",
            "Epoch 12/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 4s/step - accuracy: 0.4878 - loss: 144844432.0000 - val_accuracy: 1.0000 - val_loss: 145251456.0000\n",
            "Epoch 13/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 4s/step - accuracy: 0.5998 - loss: 213285328.0000 - val_accuracy: 1.0000 - val_loss: 175462176.0000\n",
            "Epoch 14/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 4s/step - accuracy: 0.5266 - loss: 193053696.0000 - val_accuracy: 1.0000 - val_loss: 272190880.0000\n",
            "Epoch 15/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 4s/step - accuracy: 0.6155 - loss: 281116128.0000 - val_accuracy: 1.0000 - val_loss: 320721824.0000\n",
            "Epoch 16/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 4s/step - accuracy: 0.6943 - loss: 373113344.0000 - val_accuracy: 1.0000 - val_loss: 260723168.0000\n",
            "Epoch 17/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 4s/step - accuracy: 0.6192 - loss: 475210848.0000 - val_accuracy: 1.0000 - val_loss: 438570624.0000\n",
            "Epoch 18/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 4s/step - accuracy: 0.7843 - loss: 582376768.0000 - val_accuracy: 1.0000 - val_loss: 619054784.0000\n",
            "Epoch 19/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 4s/step - accuracy: 0.7878 - loss: 663793408.0000 - val_accuracy: 1.0000 - val_loss: 705848768.0000\n",
            "Epoch 20/20\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 4s/step - accuracy: 0.6479 - loss: 742397504.0000 - val_accuracy: 1.0000 - val_loss: 485483232.0000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 482961728.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 485483232.0, Test Accuracy: 1.0\n",
            "Model and predictions saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "keras.saving.save_model(model, '/content/drive/MyDrive/cnn_classification_model_20ep.keras')"
      ],
      "metadata": {
        "id": "octvOVP_j_lb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}